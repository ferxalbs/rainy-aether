# PRICING TABLE OF PROVIDERS

## Providers

### Google

- Gemini 2.5 Flash Lite (gemini-2.5-flash-lite) | Input $0.10 / M tokens | Output $0.40 / M tokens | Cache: $0.025 / M Tokens
- Gemini 2.5 Flash (gemini-2.5-flash) | Input $0.30 / M tokens | Output $2.50 / M tokens | Cache: $0.075 / M Tokens
- Gemini 2.5 Pro (gemini-2.5-pro) | Input ≤200K $1.25 >200K $2.50 / M tokens | Output ≤200K $10.00 >200K $15.00 / M tokens | Cache: ≤200K $0.31 >200K $0.625 / M Tokens

#### Modelos de Vista Previa

- Gemini Flash Lite (gemini-flash-lite-latest) | Input $0.10 / M tokens | Output $0.40 / M tokens | Cache: $0.025 / M Tokens
- Gemini Flash (gemini-flash-latest) | Input $0.30 / M tokens | Output $2.50 / M tokens | Cache: $0.075 / M Tokens

### Groq

- Llama 3.1 8B (llama-3.1-8b-instant) | Input $0.05 / M tokens | Output $0.08 / M tokens | No use a system cache,  use Rainy Cache of Enosis Labs
- Llama 3.3 70B (llama-3.3-70b-versatile) | Input $0.59 / M tokens | Output $0.79 / M tokens | No use a provider cache, use Rainy Cache of Enosis Labs
- Llama 4 Maverick (meta-llama/llama-4-maverick-17b-128e-instruct) | Input $0.20 / M tokens | Output $0.60 / M tokens | No use a system cache, use Rainy Cache of Enosis Labs
- Kimi K2 (moonshotai/kimi-k2-instruct-0905) | Input $1.00 / M tokens | Output $3.00 / M tokens | Cache Input $0.50 / M de Tokens ([Prompt Caching Docs](https://console.groq.com/docs/prompt-caching))

### Cerebras

- Qwen 3 480B Code (qwen-3-coder-480b) | Input $2.00 / M tokens | Output $2.00 / M tokens | No use a provider cache,  use Rainy Cache of Enosis Labs.
- Llama 4 Maverick Fast (llama-4-maverick-17b-128e-instruct) | Input $0.20 / M tokens | Output $0.60 / M tokens | No use a provider cache,  use Rainy Cache of Enosis Labs.
- GPT OSS 120B Fast (gpt-oss-120b) | Input $0.35 / M tokens | Output $0.75 / M tokens | No use a provider cache,  use Rainy Cache of Enosis Labs.

### OpenRouter

#### OpenAI

- **GPT 5** (openai/gpt-5) | Input $1.25 / M tokens | Output $10.00 / M tokens | Read Cache: $0.50
- **GPT 5 Codex** (openai/gpt-5-codex) | Input $1.25 / M tokens | Output $10.00 / M tokens | Read Cache: $0.50
- **Codex Mini** (openai/codex-mini) | Input $1.75 / M tokens | Output $6.00 / M tokens | Read Cache: $0.25 / M tokens

#### Alibaba with Qwen Models

- **Qwen 3 Coder Plus** (qwen/qwen3-coder-plus) | Input ≤32K $1.00 >32K $1.85 / M tokens | Output ≤32K $5.00 >32K $9.00 / M tokens | Cache Read: ≤32K $0.10 >32K $0.18 / M tokens
- **Qwen 3 Max** (qwen/qwen3-max) | Input ≤128K $1.25 >128K $3.10 / M tokens | Output ≤128K $6.00 >128K $15.00 / M tokens | Cache Read: ≤128K $0.10 >128K $0.18 / M tokens

#### DeepSeek

- **DeepSeek Chat v3.1** (deepseek/deepseek-chat-v3.1:free) | Input $1.00 / M tokens | Output $2.00 / M tokens | Cache Read: $0.50 / M tokens

#### Anthropic

- **Claude Sonnet 4** (anthropic/claude-sonnet-4) | Input ≤200K $3.00 >200k $6.00 / M tokens | Output ≤200K $15.00 >200k $22.50 / M tokens | Cache Read: ≤200K $0.30 >200K $0.60 / M tokens | Cache Write: ≤200K $3.75 >200K $7.50 / M tokens
- Claude Opus 4 (anthropic/claude-opus-4) | Input $15.00 / M tokens | Output $75.00 / M tokens | Cache Read: $1.50 | Cache Write: $19.00
- Claude Opus 4.1 (anthropic/claude-opus-4.1) | Input $15.00 / M tokens | Output $75.00 / M tokens | Cache Read: $1.50 | Cache Write: $19.00

#### xAI

- Grok Code Fast 1 (x-ai/grok-code-fast-1) | Input $0.20 / M tokens | Output $1.50 / M tokens | Use Cache but only paid the provider with the Read Operation: Cache Read $0.02 / M
- Grok 4 Fast (x-ai/grok-4-fast) | Input ≤128K $0.20 >128K $0.40 / M tokens | Output ≤128K $0.50 >128k $1.0 / M tokens | Use Cache but only paid the provider with the Read Operation: Cache Read ≤128K $0.05 >128k $0.08 / M

#### Z.AI

- **GLM 4.5** (z-ai/glm-4.5) | Input $0.60 / M tokens | Output $0.1.80 / M tokens | No use a provider cache,  use Rainy Cache of Enosis Labs.
